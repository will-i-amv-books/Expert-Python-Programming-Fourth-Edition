{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of concurrency:\n",
    "\n",
    "* Concurrency is not the same as parallelism. \n",
    "\n",
    "* Concurrency is not a matter of application implementation. \n",
    "\n",
    "* Concurrency can be defined as follows: \"Two events are concurrent if neither can causally affect the other.\"\n",
    "\n",
    "* In other words, something is concurrent if it can be fully or partially decomposed into components (units) that are order-independent.\n",
    "\n",
    "Common application scenarios where concurrent processing is a viable approach:\n",
    "\n",
    "* Processing distribution: The scale of the problem is so big that the only way to process it in an acceptable time frame (with constrained resources) is to distribute execution on multiple processing units that can handle the work in parallel.\n",
    "\n",
    "* Application responsiveness: Your application needs to maintain responsiveness (accept new inputs), even if it did not finish processing previous inputs.\n",
    "\n",
    "* Background processing: Not every task needs to be performed in a synchronous way. If there is no need to immediately access the results of a specific action, it may be reasonable to defer execution in time.\n",
    "\n",
    "Python's tools to deal with concurrency:\n",
    "\n",
    "* Multithreading: \n",
    "    * Running multiple threads of execution that share the memory context of the parent process. \n",
    "    * The execution of threads is coordinated by the OS kernel.\n",
    "    * It works best in applications that do a lot of I/O operations or need to maintain UI responsiveness. \n",
    "    * Very lightweight, but comes with caveats and memory safety risks.\n",
    "\n",
    "* Multiprocessing: \n",
    "    * Running multiple independent processes to perform work in a distributed manner. \n",
    "    * Similar to threads in operation, but there's no shared memory context. \n",
    "    * Due to Python's GIL limitaton, it's better suited for CPU-intensive applications. \n",
    "    * More heavyweight than multithreading and requires implementing inter-process communication patterns to orchestrate work between processes.\n",
    "\n",
    "* Asynchronous programming: \n",
    "    * Running multiple cooperative tasks within a single application process. \n",
    "    * Cooperative tasks work like threads, but switching between them is done by the application, not the OS kernel. \n",
    "    * Well suited to I/O-bound applications, especially for programs that need to handle multiple simultaneous network connections. \n",
    "    * The downside of asynchronous programming is the need to use dedicated asynchronous libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a new thread in Python, use the `threading.Thread()` class, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting thread...\n",
      "printing from thread\n",
      "Ending thread...\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/start_new_thread.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code example:\n",
    "\n",
    "* To start a new thread, we call the `start()` method.\n",
    "\n",
    "* Once the new thread is started, it'll run next to the main thread until the target function finishes. \n",
    "\n",
    "* To end the thread, we wait for the thread to finish with the `join()` method, which is a blocking operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a small modification, we can also start and join multiple threads in bulk, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threads...\n",
      "\n",
      "printing from thread\n",
      "printing from threadprinting from thread\n",
      "\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from threadprinting from thread\n",
      "\n",
      "Ending threads...\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/start_new_threads.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread safety:\n",
    "\n",
    "* All threads share the same memory context, so we must be careful when many threads access the same data structures. \n",
    "\n",
    "* If 2 parallel threads update the same variable without any protection, there might be a situation where a subtle timing variation in thread execution can alter the final result in an unexpected way. \n",
    "\n",
    "* Such situations are called `race conditions`, and they're very hard to debug. In those cases, the code is not 'thread-safe'.\n",
    "\n",
    "For example, the following program is not thread-safe, and it returns a different value in every execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_count=100, thread_visits=9594669\n"
     ]
    }
   ],
   "source": [
    "# The correct output is 100 threads * 100.000 iterations = 10.000.000\n",
    "\n",
    "!python _01_multithreading/thread_visits.py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid race conditions, we need to to use thread locking primitives. Python provides the `threading.Lock` class, which is a simple implementation of a thread lock. \n",
    "\n",
    "The following is an example of a thread-safe variant of the last code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_count=100, thread_visits=10000000\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/thread_safe_visits.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last code example, the thread visits with locks are counted properly, but at the expense of lower performance: \n",
    "\n",
    "* The lock will make sure that only 1 thread at a time can process a single block of code, so the protected block cannot run in parallel. \n",
    "\n",
    "* Also, acquiring and releasing locks are operations that add overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python's limitation with threads:\n",
    "\n",
    "The standard implementation of Python (the CPython interpreter) comes with a major limitation that renders threads less useful in many contexts: \n",
    "\n",
    "* All operations accessing Python objects are serialized by the `Global Interpreter Lock (GIL)`.\n",
    "\n",
    "* This is done because many of the interpreter's internal structures are not thread-safe and need to be protected. \n",
    "\n",
    "* Not every operation requires locking, and there are certain situations when threads release the lock:\n",
    "    * In blocking system calls like socket calls.     \n",
    "    * In sections of C extensions that do not use any Python/C API functions.\n",
    "\n",
    "* So multiple threads can do I/O operations or execute some C extension code completely in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple multithreaded application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a program that fetches foreign exchange rates from an external source:\n",
    "\n",
    "* The exchange rates are available from a free API at `https://www.vatcomply.com`. \n",
    "\n",
    "* We want to obtain exchange rates for multiple currencies and present the results as an exchange rate currency matrix.\n",
    "\n",
    "* But the API doesn't allow us to query for data using multiple base currencies at once, so we need to fetch them one by one.\n",
    "\n",
    "The following is a naive synchronous solution that doesn't use threads at all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 4.82s\n"
     ]
    }
   ],
   "source": [
    "!python _02_example_threaded_application/synchronous.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last code example is mostly I/O bound, so we can improve it with multithreading. The simplest approach is to use one thread per parameter value (defined in `SYMBOLS`) , as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "\n",
      "time elapsed: 1.42s\n"
     ]
    }
   ],
   "source": [
    "!python _03_one_thread_per_item/one_thread_per_item.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last code example shows substantial improvement. But there are issues with it:\n",
    "\n",
    "* We start a new thread for every parameter:\n",
    "\n",
    "    * Thread initialization takes time and consume resources like memory or file descriptors. \n",
    "    * Our example input has a small number of items, but it's not a good idea to run an unbound number of threads that depend on the size of data input.\n",
    "\n",
    "* The `fetch_rates()` function calls the built-in `print()` function:\n",
    "\n",
    "    * `print()` has issues due to the way the standard output is buffered in Python, which may cause malformed output when multiple function calls interweave between threads.\n",
    "    * `print()` is slow; so if used in many threads, it can lead to slow function executions that will erase any gains from multithreading.\n",
    "\n",
    "* By delegating every function call to a separate thread, it's hard to control the rate of network calls:\n",
    "\n",
    "    * External services enforce limits on the rate of requests from a single client. \n",
    "    * So it's a good idea to apply throttling to the rate of processing, to avoid being blacklisted by APIs for abusing their usage limits.\n",
    "\n",
    "We can fix the 1st and 3rd issue with thread pools:\n",
    "\n",
    "* Thread pools start a predefined number of threads that will consume the work items from a queue until it becomes empty. \n",
    "\n",
    "* When there is no more work to do, the threads will quit, so we'll be able to exit from the program. \n",
    "\n",
    "* The `Queue` class from the `queue` module can be used. It's a thread-safe FIFO queue implementation. \n",
    "\n",
    "The following is a modified versionof the last code that uses a thread pool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "\n",
      "time elapsed: 1.15s\n"
     ]
    }
   ],
   "source": [
    "!python _04_Using_thread_pool/thread_pool.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified function still has the 2nd issue unsolved: the malformed output when 2 threads attempt to print results at the same time. That can bee fixed by using 2-way queues:\n",
    "\n",
    "* We use another queue responsible for collecting results from our workers. \n",
    "\n",
    "* Then the main threadprints the results from the 2nd queue.\n",
    "\n",
    "The following is the modified code that uses 2-way queues:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.08s\n"
     ]
    }
   ],
   "source": [
    "!python _05_Using_2way_queues/two_way_queues.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhandled exceptions in threads:\n",
    "\n",
    "* If there's an exception in the thread making the request, that thread will exit immediately but won't crash the entire program.\n",
    "\n",
    "* But the main thread will wait for all tasks to finish, so we end up in a situation where some of the worker threads crashed and the program will never exit.\n",
    "\n",
    "* To avoid this, the worker threads should handle possible exceptions and make sure that all items from the queue are processed.\n",
    "\n",
    "So in case there are exceptions in a worker thread: \n",
    "\n",
    "* We put an exception instance on the `results_queue` queue. \n",
    "\n",
    "* We mark the task as done, even if there was an error; so the main thread won't lock indefinitely.\n",
    "\n",
    "* The main thread will inspect the results and reraise any exceptions found on the results queue. \n",
    "\n",
    "The following is the improved versions of the app, with the changes described above (We simulate exceptions by randomly changing the status code of a request to 500 (Internal Server Error).):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 81, in <module>\n",
      "    main()\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 75, in main\n",
      "    raise result\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 49, in worker\n",
      "    result = fetch_rates(item)\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 27, in fetch_rates\n",
      "    response.raise_for_status()\n",
      "  File \"/home/work/.cache/pypoetry/virtualenvs/expert-python-programming-fourth-edition-em7utuy--py3.10/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 500 Server Error: OK for url: https://api.vatcomply.com/rates?base=EUR\n"
     ]
    }
   ],
   "source": [
    "!python _06_errors_in_threads/error_handling.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last modified code still can't handle potential rate limits imposed by external service providers:\n",
    "\n",
    "* Many services (even paid ones) often do impose rate limits.\n",
    "\n",
    "* When a service has rate limits, it starts returning responses indicating errors after a certain number of requests are made, surpassing the allocated quota. \n",
    "\n",
    "* Exception handling is not enough to properly handle rate limits, because services often count requests made beyond the limit, and if you go beyond the limit consistently, you never get back to the allocated quota.\n",
    "\n",
    "So we'll apply throttling to our thread pool. The algorithm we'll use is a `token bucket`:\n",
    "\n",
    "* There is a bucket with a predefined number of tokens.\n",
    "\n",
    "* Each token corresponds to a single permission to process one item of work\n",
    "\n",
    "* Each time the worker asks for one or more tokens, we do the following:\n",
    "    1. We check how much time has passed since the last time we refilled the bucket.\n",
    "    2. If the time difference allows for it, we refill the bucket with the number of tokens that correspond to the time difference\n",
    "    3. If the number of stored tokens is bigger than or equal to the amount requested, we decrease the number of stored tokens and return that value\n",
    "    4. If the number of stored tokens is less than requested, we return zero.\n",
    "\n",
    "The following is a modified implementation of the last code example, that allows for throttling with the token bucket algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 0.97s\n"
     ]
    }
   ],
   "source": [
    "!python _07_Throttling/throttling.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last exmple:\n",
    "\n",
    "* The `main()` function uses the throttle instance of `Throttle`, that can be shared across threads since it's thread-safe.\n",
    "\n",
    "* The `worker()` function receives the throttle instance as arg, and waits with every item until the throttle object releases a new token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to achieve parallelism is multiprocessing:\n",
    "\n",
    "* Multiple processes don't constrain each other with the GIL and allow for better resource utilization. \n",
    "\n",
    "* Also, multiple processes don't share a memory context, so it's harder to corrupt data and introduce race conditions in your application. \n",
    "\n",
    "* This requires passing data between separate processes, but Python provides primitives to implement inter-process communication. \n",
    "\n",
    "The basic way to start new processes is by forking the program at some point. In Python it is exposed through the `os.fork()` function.\n",
    "\n",
    "The following is a script that forks itself exactly once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRNT: hey, I am the parent \n",
      "PRNT: the child pid is 11906\n",
      "PRNT: all the pids I know: [11905, 11905]\n",
      "\n",
      "CHLD: hey, I am the child process\n",
      "CHLD: all the pids I know: [11905, 11906]\n"
     ]
    }
   ],
   "source": [
    "!python _08_Multiprocessing/forks.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code xample:\n",
    "\n",
    "* `os.fork()` spawns a new process and returns an integer value. If it's 0, the current process is a child process. \n",
    "\n",
    "* Both processes have the same initial state before the `os.fork()` call. They both have the same PID number as a 1st value of `pid_list`.\n",
    "\n",
    "* Then, both states diverge. Both processes added different PID values to `pid_list`. This is because the memory contexts of these two processes are not shared. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiprocessing` module provides a simple way to work with processes as if they were threads. \n",
    "\n",
    "The folowing is a simple script that shows a simple implementation of `multiprocessing`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, I am the process 0, pid: 11908\n",
      "Hey, I am the process 1, pid: 11909\n",
      "Hey, I am the process 2, pid: 11910\n",
      "Hey, I am the process 3, pid: 11911\n",
      "Hey, I am the process 4, pid: 11912\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/basic_multiprocessing.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiprocessing` module provides the following ways of communicating between processes:\n",
    "\n",
    "* The `multiprocessing.Queue` class, which is a functional equivalent of `queue.Queue`.\n",
    "\n",
    "* The `multiprocessing.Pipe`, which is a socket-like two-way communication channel.\n",
    "\n",
    "* The `multiprocessing.sharedctypes` module, which allows us to create arbitrary C types (from the `ctypes` module) in a dedicated pool of memory shared between processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the communication pattern between processes is provided by the `Pipe` class:\n",
    "\n",
    "* It's a 2-way communication channel similar in concept to UNIX pipes.\n",
    "\n",
    "* It allows us to send almost almost any basic Python type. \n",
    "\n",
    "The following is an example script that reads objects from the `Pipe` object and output their representation on standard output (Notice how custom class instances have different addresses, depending on the process):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRNT: send: 42\n",
      "PRNT: send: some string\n",
      "PRNT: send: {'one': 1}\n",
      "PRNT: send: <__main__.CustomClass object at 0x7f034dc6b760>\n",
      "PRNT: send: None\n",
      "CHLD: recv: 42\n",
      "CHLD: recv: some string\n",
      "CHLD: recv: {'one': 1}\n",
      "CHLD: recv: <__main__.CustomClass object at 0x7f034dac28f0>\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/pipes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other communication pattern between processes is to use raw types in a shared memory pool with classes provided in `multiprocessing.sharedctypes`. \n",
    "\n",
    "The following shows an example code from the official documentation of `multiprocessing`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415927\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/sharedctypes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process pools:\n",
    "\n",
    "* The `multiprocessing` module allows us to reduce the amount of boilerplate thanks to extra functionalities, such as process pools. \n",
    "\n",
    "* Process pools allows us to control resource usage in applications that rely on multiprocessing.\n",
    "\n",
    "* multiprocessing provides a `Pool` class that handles the complexity of managing multiple process workers. \n",
    "\n",
    "The following is a modified example of a thread pool used before, rewritten to use the `Pool` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.12s\n"
     ]
    }
   ],
   "source": [
    "!python _10_process_pools/process_pools.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread pools with `multiprocessing.pool`:\n",
    "\n",
    "* There are use cases where threads are a better solution than processes, especially where low latency and/or high resource efficiency are required.\n",
    "\n",
    "* `multiprocessing` provides the `multiprocessing.pool.ThreadPool` class, which replicates the multiprocessing API but uses threads instead of processes.\n",
    "\n",
    "The following shows the last code example modified to use thread pools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 0.88s\n"
     ]
    }
   ],
   "source": [
    "!python _11_Using_multiprocessing_dummy/multiprocessing_dummy.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cooperative multitasking:\n",
    "\n",
    "* Cooperative multitasking is at the core of asynchronous programming. \n",
    "\n",
    "* In this style of multitasking, it's not the responsibility of the OS to initiate a context switch (to another process or thread). \n",
    "\n",
    "* Instead, every task voluntarily releases the control when it's idle to enable the simultaneous execution of multiple tasks.\n",
    "\n",
    "Cooperative multitasking is done at the application level:\n",
    "\n",
    "* We don't deal with threads or processes, because all the execution is contained within a single process and thread. \n",
    "\n",
    "* Instead, we have multiple tasks (coroutines, green threads, etc.) that release the control to the single function that handles the coordination of tasks. This function is called the `event loop`.\n",
    "\n",
    "This approach is somewhat similar to multithreading:\n",
    "\n",
    "* We know that the GIL serializes Python threads, but it's also released on every I/O operation. \n",
    "\n",
    "* Threads in Python are implemented as system-level threads so that the OS can preempt the currently running thread and give control to other threads at any point in time. \n",
    "\n",
    "* But in async programming, tasks are never preempted by the main event loop and must return control explicitly. That's why this is called `non-preemptive multitasking`. \n",
    "\n",
    "* This reduces time lost on context switching and plays better with CPython's GIL implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `async` and `await` keywords: \n",
    "\n",
    "* The `async` keyword, when used before the `def` statement, defines a new coroutine.\n",
    "\n",
    "* Its syntax and behavior are very similar to generators. \n",
    "\n",
    "* When calling functions defined with the `async` keyword, they don't execute the code inside, but instead return a coroutine object.\n",
    "\n",
    "Consider the following example of a simple async function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object async_hello at 0x7f1d91456490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def async_hello():\n",
    "    print(\"hello, world!\")\n",
    "\n",
    "\n",
    "async_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code example:\n",
    "\n",
    "* The coroutine object doesn't do absolutely anything. \n",
    "\n",
    "* To execute it, we need to schedule it in the event loop. \n",
    "\n",
    "* The `asyncio` module provides the event loop implementation and other async utilities. \n",
    "\n",
    "The following shows how to schedule a coroutine execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "!python _12_async_await/basic_async.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code example:\n",
    "\n",
    "* There is no concurrency involved in our program.. To see something that's concurrent, we'll create many tasks that will be executed by the event loop.\n",
    "\n",
    "* A single task can be added to the loop by calling the `loop.create_task()` method or by providing an \"awaitable\" object to `asyncio.wait()`. \n",
    "\n",
    "* But if there are multiple tasks to wait for, we can use `asyncio.gather()` to aggregate them into a single object. \n",
    "\n",
    "The following shows a script that print asynchronously a sequence of numbers generated with the `range()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "8\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "4\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "!python _12_async_await/async_print.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asyncio.gather() function:\n",
    "\n",
    "* Accepts a variable number coroutine objects as args. \n",
    "\n",
    "* Returns an object that represents a future result (a so-called `future`) of running all of the provided coroutines. \n",
    "\n",
    "* With the `await asyncio.sleep(random.random())` line, the coroutines can interweave with each other.\n",
    "\n",
    "We can't achieve the same thing in the last example just by using `time.sleep()`. To see why, consider a program that uses 2 coroutines to perform the same task in a loop:\n",
    "\n",
    "* Wait a random number of seconds\n",
    "\n",
    "* Print some text provided as an argument and the amount of time spent in sleep\n",
    "\n",
    "The following is a naive implementation that doesn't use the `await` keyword:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first waited 0.25 seconds\n",
      "first waited 0.75 seconds\n",
      "first waited 0.75 seconds\n",
      "first waited 0.75 seconds\n",
      "second waited 0.25 seconds\n",
      "second waited 0.75 seconds\n",
      "second waited 0.5 seconds\n",
      "second waited 0.25 seconds\n"
     ]
    }
   ],
   "source": [
    "!python _12_async_await/waiters.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last example:\n",
    "\n",
    "* Both coroutines completed their execution, but not in an async manner. \n",
    "\n",
    "* Both use `time.sleep()`, which is blocking but not releasing the control to the event loop. \n",
    "\n",
    "* To fix this, we need to use `asyncio.sleep()`, which is the async version of time.sleep(), and await its result using the `await` keyword. \n",
    "\n",
    "The following is a modified implementation of the last example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first waited 0.75 seconds\n",
      "second waited 0.75 seconds\n",
      "first waited 0.5 seconds\n",
      "second waited 0.75 seconds\n",
      "first waited 0.25 seconds\n",
      "second waited 0.5 seconds\n",
      "first waited 0.5 seconds\n",
      "second waited 0.25 seconds\n"
     ]
    }
   ],
   "source": [
    "!python _12_async_await/waiters_await.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last example in mind, we can modify the FOREX fetching app implemented before, but using async programming:\n",
    "\n",
    "* But the `requests` library doesn't support asynchronous I/O with the `async` and `await` keywords. \n",
    "\n",
    "* Instead, we'll use the `aiohttp` library, which is available on PyPI.\n",
    "\n",
    "The following shows the modified implementation of the FOREX fetching app:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.14s\n"
     ]
    }
   ],
   "source": [
    "!python _13_example_async_programming/async_aiohttp.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last example:\n",
    "\n",
    "* As an upside, we didn't have to deal with process pools and memory safety to achieve concurrent network communication, compared to other concurrency models. \n",
    "\n",
    "* As a downside, we couldn't use a popular sync-only library like `requests`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating non-async code with async using futures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async programming is great for building scalable applications. But many Python packages that deal with I/O-bound problems are incompatible with async code. The main reasons are:\n",
    "\n",
    "* The low adoption of advanced Python 3 features (especially async programming).\n",
    "\n",
    "* The low understanding of various concurrency concepts among Python beginners.\n",
    "\n",
    "* This means that the migration of synchronous multithreaded apps and packages is either impossible or too expensive. \n",
    "\n",
    "In summary, when writing async applications, you may have:\n",
    "\n",
    "* Code that makes long synchronous I/O operations that you can't or are unwilling to rewrite. \n",
    "\n",
    "* Code that makes heavy CPU-bound operations in an application designed mostly with asynchronous I/O in mind. \n",
    "\n",
    "For those cases: \n",
    "\n",
    "* The Python standard library provides the `concurrent.futures` module, which is integrated with the `asyncio` module. \n",
    "\n",
    "* These 2 modules together allow us to schedule blocking functions to execute in threads or processes as if they were async non-blocking coroutines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important classes in the concurrent.futures module are `Executor` and `Future`.\n",
    "\n",
    "* `Executor` represents a pool of resources that process work items in parallel. \n",
    "\n",
    "* The `Executor` class has the following 2 implementations:\n",
    "    * `ThreadPoolExecutoR`: represents a pool of threads\n",
    "    * `ProcessPoolExecutor`: represents a pool of processes\n",
    "\n",
    "* Every executor provides the following 3 methods:\n",
    "    * `submit(func, *args, **kwargs)`: schedules the `func` function for execution in a pool of resources and returns the `Future` object representing the execution of a callable.\n",
    "    * `map(func, *iterables, timeout=None, chunksize=1)`: executes the `func` function over an iterable, similar to `multiprocessing.Pool.map()`\n",
    "    * `shutdown(wait=True)`: shuts down the executor and frees all of its resources.\n",
    "\n",
    "The most interesting method is `submit()`: \n",
    "\n",
    "* It represents the async execution of the callable and only indirectly represents its result. \n",
    "\n",
    "* To obtain the actual return value of the submitted callable, you need to call the `Future.result()` method.\n",
    "\n",
    "* If the callable has finished, the `result()` method won't block and will return the function output. \n",
    "\n",
    "* If the callable hasn't finished, it will block until the result is ready. \n",
    "\n",
    "Consider the following basic usage of `ThreadPoolExecutor`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def loudly_return():\n",
    "    print(\"processing\")\n",
    "    return 42\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(1) as executor:\n",
    "    future = executor.submit(loudly_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x7fee2c37c430 state=finished returned int>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use executors to make a hybrid between cooperative multitasking and multiprocessing/multithreading.\n",
    "\n",
    "* We can do it with the `run_in_executor(executor, func, *args)` method of the event loop class. \n",
    "\n",
    "* It allows us to schedule the execution of the `func` function in a process/thread pool represented by the `executor` arg. \n",
    "\n",
    "* If we passs `None` as `executor` arg, the `ThreadPoolExecutor` class will be used with the default number of threads (for Python 3.9, the number of processors multiplied by 5).\n",
    "\n",
    "* It returns a new awaitable (an object that can be awaited with the `await` statement), so we can execute a blocking function that's not a coroutine as if it was a coroutine. \n",
    "\n",
    "* Also, it won't block the event loop from processing other coroutines, no matter how long it will take to finish. It will stop only the function that is awaiting results from such a call.\n",
    "\n",
    "So, instead of rewriting the FOREX fetching code to use a dedicated async library, we can defer the blocking call to a separate thread with the `loop.run_in_executor()` call, while still leaving the `fetch_rates()` function as an awaitable coroutine, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.914 EUR,    3.97 PLN,    10.3 NOK,    22.4 CZK\n",
      "1 EUR =    1.09 USD,     1.0 EUR,    4.34 PLN,    11.3 NOK,    24.5 CZK\n",
      "1 PLN =   0.252 USD,    0.23 EUR,     1.0 PLN,     2.6 NOK,    5.65 CZK\n",
      "1 NOK =  0.0969 USD,  0.0886 EUR,   0.385 PLN,     1.0 NOK,    2.17 CZK\n",
      "1 CZK =  0.0446 USD,  0.0408 EUR,   0.177 PLN,    0.46 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.43s\n"
     ]
    }
   ],
   "source": [
    "!python _14_Integrating_sync_and_async_code/async_futures.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expert-python-programming-fourth-edition-em7utuy--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
