{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of concurrency:\n",
    "\n",
    "* Concurrency is not the same as parallelism. \n",
    "\n",
    "* Concurrency is not a matter of application implementation. \n",
    "\n",
    "* Concurrency can be defined as follows: \"Two events are concurrent if neither can causally affect the other.\"\n",
    "\n",
    "* In other words, something is concurrent if it can be fully or partially decomposed into components (units) that are order-independent.\n",
    "\n",
    "Common application scenarios where concurrent processing is a viable approach:\n",
    "\n",
    "* Processing distribution: The scale of the problem is so big that the only way to process it in an acceptable time frame (with constrained resources) is to distribute execution on multiple processing units that can handle the work in parallel.\n",
    "\n",
    "* Application responsiveness: Your application needs to maintain responsiveness (accept new inputs), even if it did not finish processing previous inputs.\n",
    "\n",
    "* Background processing: Not every task needs to be performed in a synchronous way. If there is no need to immediately access the results of a specific action, it may be reasonable to defer execution in time.\n",
    "\n",
    "Python's tools to deal with concurrency:\n",
    "\n",
    "* Multithreading: \n",
    "    * Running multiple threads of execution that share the memory context of the parent process. \n",
    "    * The execution of threads is coordinated by the OS kernel.\n",
    "    * It works best in applications that do a lot of I/O operations or need to maintain UI responsiveness. \n",
    "    * Very lightweight, but comes with caveats and memory safety risks.\n",
    "\n",
    "* Multiprocessing: \n",
    "    * Running multiple independent processes to perform work in a distributed manner. \n",
    "    * Similar to threads in operation, but there's no shared memory context. \n",
    "    * Due to Python's GIL limitaton, it's better suited for CPU-intensive applications. \n",
    "    * More heavyweight than multithreading and requires implementing inter-process communication patterns to orchestrate work between processes.\n",
    "\n",
    "* Asynchronous programming: \n",
    "    * Running multiple cooperative tasks within a single application process. \n",
    "    * Cooperative tasks work like threads, but switching between them is done by the application, not the OS kernel. \n",
    "    * Well suited to I/O-bound applications, especially for programs that need to handle multiple simultaneous network connections. \n",
    "    * The downside of asynchronous programming is the need to use dedicated asynchronous libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a new thread in Python, use the `threading.Thread()` class, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting thread...\n",
      "printing from thread\n",
      "Ending thread...\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/start_new_thread.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code example:\n",
    "\n",
    "* To start a new thread, we call the `start()` method.\n",
    "\n",
    "* Once the new thread is started, it'll run next to the main thread until the target function finishes. \n",
    "\n",
    "* To end the thread, we wait for the thread to finish with the `join()` method, which is a blocking operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a small modification, we can also start and join multiple threads in bulk, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threads...\n",
      "\n",
      "printing from thread\n",
      "printing from threadprinting from thread\n",
      "\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from thread\n",
      "printing from threadprinting from thread\n",
      "\n",
      "Ending threads...\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/start_new_threads.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread safety:\n",
    "\n",
    "* All threads share the same memory context, so we must be careful when many threads access the same data structures. \n",
    "\n",
    "* If 2 parallel threads update the same variable without any protection, there might be a situation where a subtle timing variation in thread execution can alter the final result in an unexpected way. \n",
    "\n",
    "* Such situations are called `race conditions`, and they're very hard to debug. In those cases, the code is not 'thread-safe'.\n",
    "\n",
    "For example, the following program is not thread-safe, and it returns a different value in every execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_count=100, thread_visits=9594669\n"
     ]
    }
   ],
   "source": [
    "# The correct output is 100 threads * 100.000 iterations = 10.000.000\n",
    "\n",
    "!python _01_multithreading/thread_visits.py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid race conditions, we need to to use thread locking primitives. Python provides the `threading.Lock` class, which is a simple implementation of a thread lock. \n",
    "\n",
    "The following is an example of a thread-safe variant of the last code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_count=100, thread_visits=10000000\n"
     ]
    }
   ],
   "source": [
    "!python _01_multithreading/thread_safe_visits.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last code example, the thread visits with locks are counted properly, but at the expense of lower performance: \n",
    "\n",
    "* The lock will make sure that only 1 thread at a time can process a single block of code, so the protected block cannot run in parallel. \n",
    "\n",
    "* Also, acquiring and releasing locks are operations that add overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python's limitation with threads:\n",
    "\n",
    "The standard implementation of Python (the CPython interpreter) comes with a major limitation that renders threads less useful in many contexts: \n",
    "\n",
    "* All operations accessing Python objects are serialized by the `Global Interpreter Lock (GIL)`.\n",
    "\n",
    "* This is done because many of the interpreter's internal structures are not thread-safe and need to be protected. \n",
    "\n",
    "* Not every operation requires locking, and there are certain situations when threads release the lock:\n",
    "    * In blocking system calls like socket calls.     \n",
    "    * In sections of C extensions that do not use any Python/C API functions.\n",
    "\n",
    "* So multiple threads can do I/O operations or execute some C extension code completely in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple multithreaded application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a program that fetches foreign exchange rates from an external source:\n",
    "\n",
    "* The exchange rates are available from a free API at `https://www.vatcomply.com`. \n",
    "\n",
    "* We want to obtain exchange rates for multiple currencies and present the results as an exchange rate currency matrix.\n",
    "\n",
    "* But the API doesn't allow us to query for data using multiple base currencies at once, so we need to fetch them one by one.\n",
    "\n",
    "The following is a naive synchronous solution that doesn't use threads at all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 4.82s\n"
     ]
    }
   ],
   "source": [
    "!python _02_example_threaded_application/synchronous.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last code example is mostly I/O bound, so we can improve it with multithreading. The simplest approach is to use one thread per parameter value (defined in `SYMBOLS`) , as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "\n",
      "time elapsed: 1.42s\n"
     ]
    }
   ],
   "source": [
    "!python _03_one_thread_per_item/one_thread_per_item.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last code example shows substantial improvement. But there are issues with it:\n",
    "\n",
    "* We start a new thread for every parameter:\n",
    "\n",
    "    * Thread initialization takes time and consume resources like memory or file descriptors. \n",
    "    * Our example input has a small number of items, but it's not a good idea to run an unbound number of threads that depend on the size of data input.\n",
    "\n",
    "* The `fetch_rates()` function calls the built-in `print()` function:\n",
    "\n",
    "    * `print()` has issues due to the way the standard output is buffered in Python, which may cause malformed output when multiple function calls interweave between threads.\n",
    "    * `print()` is slow; so if used in many threads, it can lead to slow function executions that will erase any gains from multithreading.\n",
    "\n",
    "* By delegating every function call to a separate thread, it's hard to control the rate of network calls:\n",
    "\n",
    "    * External services enforce limits on the rate of requests from a single client. \n",
    "    * So it's a good idea to apply throttling to the rate of processing, to avoid being blacklisted by APIs for abusing their usage limits.\n",
    "\n",
    "We can fix the 1st and 3rd issue with thread pools:\n",
    "\n",
    "* Thread pools start a predefined number of threads that will consume the work items from a queue until it becomes empty. \n",
    "\n",
    "* When there is no more work to do, the threads will quit, so we'll be able to exit from the program. \n",
    "\n",
    "* The `Queue` class from the `queue` module can be used. It's a thread-safe FIFO queue implementation. \n",
    "\n",
    "The following is a modified versionof the last code that uses a thread pool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "\n",
      "time elapsed: 1.15s\n"
     ]
    }
   ],
   "source": [
    "!python _04_Using_thread_pool/thread_pool.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified function still has the 2nd issue unsolved: the malformed output when 2 threads attempt to print results at the same time. That can bee fixed by using 2-way queues:\n",
    "\n",
    "* We use another queue responsible for collecting results from our workers. \n",
    "\n",
    "* Then the main threadprints the results from the 2nd queue.\n",
    "\n",
    "The following is the modified code that uses 2-way queues:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.08s\n"
     ]
    }
   ],
   "source": [
    "!python _05_Using_2way_queues/two_way_queues.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhandled exceptions in threads:\n",
    "\n",
    "* If there's an exception in the thread making the request, that thread will exit immediately but won't crash the entire program.\n",
    "\n",
    "* But the main thread will wait for all tasks to finish, so we end up in a situation where some of the worker threads crashed and the program will never exit.\n",
    "\n",
    "* To avoid this, the worker threads should handle possible exceptions and make sure that all items from the queue are processed.\n",
    "\n",
    "So in case there are exceptions in a worker thread: \n",
    "\n",
    "* We put an exception instance on the `results_queue` queue. \n",
    "\n",
    "* We mark the task as done, even if there was an error; so the main thread won't lock indefinitely.\n",
    "\n",
    "* The main thread will inspect the results and reraise any exceptions found on the results queue. \n",
    "\n",
    "The following is the improved versions of the app, with the changes described above (We simulate exceptions by randomly changing the status code of a request to 500 (Internal Server Error).):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 81, in <module>\n",
      "    main()\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 75, in main\n",
      "    raise result\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 49, in worker\n",
      "    result = fetch_rates(item)\n",
      "  File \"/home/work/Documents/Github/will-i-amv-books/Expert-Python-Programming-Fourth-Edition/Chapter_6/_06_errors_in_threads/error_handling.py\", line 27, in fetch_rates\n",
      "    response.raise_for_status()\n",
      "  File \"/home/work/.cache/pypoetry/virtualenvs/expert-python-programming-fourth-edition-em7utuy--py3.10/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 500 Server Error: OK for url: https://api.vatcomply.com/rates?base=EUR\n"
     ]
    }
   ],
   "source": [
    "!python _06_errors_in_threads/error_handling.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last modified code still can't handle potential rate limits imposed by external service providers:\n",
    "\n",
    "* Many services (even paid ones) often do impose rate limits.\n",
    "\n",
    "* When a service has rate limits, it starts returning responses indicating errors after a certain number of requests are made, surpassing the allocated quota. \n",
    "\n",
    "* Exception handling is not enough to properly handle rate limits, because services often count requests made beyond the limit, and if you go beyond the limit consistently, you never get back to the allocated quota.\n",
    "\n",
    "So we'll apply throttling to our thread pool. The algorithm we'll use is a `token bucket`:\n",
    "\n",
    "* There is a bucket with a predefined number of tokens.\n",
    "\n",
    "* Each token corresponds to a single permission to process one item of work\n",
    "\n",
    "* Each time the worker asks for one or more tokens, we do the following:\n",
    "    1. We check how much time has passed since the last time we refilled the bucket.\n",
    "    2. If the time difference allows for it, we refill the bucket with the number of tokens that correspond to the time difference\n",
    "    3. If the number of stored tokens is bigger than or equal to the amount requested, we decrease the number of stored tokens and return that value\n",
    "    4. If the number of stored tokens is less than requested, we return zero.\n",
    "\n",
    "The following is a modified implementation of the last code example, that allows for throttling with the token bucket algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 0.97s\n"
     ]
    }
   ],
   "source": [
    "!python _07_Throttling/throttling.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last exmple:\n",
    "\n",
    "* The `main()` function uses the throttle instance of `Throttle`, that can be shared across threads since it's thread-safe.\n",
    "\n",
    "* The `worker()` function receives the throttle instance as arg, and waits with every item until the throttle object releases a new token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to achieve parallelism is multiprocessing:\n",
    "\n",
    "* Multiple processes don't constrain each other with the GIL and allow for better resource utilization. \n",
    "\n",
    "* Also, multiple processes don't share a memory context, so it's harder to corrupt data and introduce race conditions in your application. \n",
    "\n",
    "* This requires passing data between separate processes, but Python provides primitives to implement inter-process communication. \n",
    "\n",
    "The basic way to start new processes is by forking the program at some point. In Python it is exposed through the `os.fork()` function.\n",
    "\n",
    "The following is a script that forks itself exactly once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRNT: hey, I am the parent \n",
      "PRNT: the child pid is 11906\n",
      "PRNT: all the pids I know: [11905, 11905]\n",
      "\n",
      "CHLD: hey, I am the child process\n",
      "CHLD: all the pids I know: [11905, 11906]\n"
     ]
    }
   ],
   "source": [
    "!python _08_Multiprocessing/forks.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last code xample:\n",
    "\n",
    "* `os.fork()` spawns a new process and returns an integer value. If it's 0, the current process is a child process. \n",
    "\n",
    "* Both processes have the same initial state before the `os.fork()` call. They both have the same PID number as a 1st value of `pid_list`.\n",
    "\n",
    "* Then, both states diverge. Both processes added different PID values to `pid_list`. This is because the memory contexts of these two processes are not shared. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiprocessing` module provides a simple way to work with processes as if they were threads. \n",
    "\n",
    "The folowing is a simple script that shows a simple implementation of `multiprocessing`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, I am the process 0, pid: 11908\n",
      "Hey, I am the process 1, pid: 11909\n",
      "Hey, I am the process 2, pid: 11910\n",
      "Hey, I am the process 3, pid: 11911\n",
      "Hey, I am the process 4, pid: 11912\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/basic_multiprocessing.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiprocessing` module provides the following ways of communicating between processes:\n",
    "\n",
    "* The `multiprocessing.Queue` class, which is a functional equivalent of `queue.Queue`.\n",
    "\n",
    "* The `multiprocessing.Pipe`, which is a socket-like two-way communication channel.\n",
    "\n",
    "* The `multiprocessing.sharedctypes` module, which allows us to create arbitrary C types (from the `ctypes` module) in a dedicated pool of memory shared between processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the communication pattern between processes is provided by the `Pipe` class:\n",
    "\n",
    "* It's a 2-way communication channel similar in concept to UNIX pipes.\n",
    "\n",
    "* It allows us to send almost almost any basic Python type. \n",
    "\n",
    "The following is an example script that reads objects from the `Pipe` object and output their representation on standard output (Notice how custom class instances have different addresses, depending on the process):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRNT: send: 42\n",
      "PRNT: send: some string\n",
      "PRNT: send: {'one': 1}\n",
      "PRNT: send: <__main__.CustomClass object at 0x7f034dc6b760>\n",
      "PRNT: send: None\n",
      "CHLD: recv: 42\n",
      "CHLD: recv: some string\n",
      "CHLD: recv: {'one': 1}\n",
      "CHLD: recv: <__main__.CustomClass object at 0x7f034dac28f0>\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/pipes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other communication pattern between processes is to use raw types in a shared memory pool with classes provided in `multiprocessing.sharedctypes`. \n",
    "\n",
    "The following shows an example code from the official documentation of `multiprocessing`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415927\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "!python _09_The_multiprocessing_module/sharedctypes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process pools:\n",
    "\n",
    "* The `multiprocessing` module allows us to reduce the amount of boilerplate thanks to extra functionalities, such as process pools. \n",
    "\n",
    "* Process pools allows us to control resource usage in applications that rely on multiprocessing.\n",
    "\n",
    "* multiprocessing provides a `Pool` class that handles the complexity of managing multiple process workers. \n",
    "\n",
    "The following is a modified example of a thread pool used before, rewritten to use the `Pool` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 1.12s\n"
     ]
    }
   ],
   "source": [
    "!python _10_process_pools/process_pools.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread pools with `multiprocessing.pool`:\n",
    "\n",
    "* There are use cases where threads are a better solution than processes, especially where low latency and/or high resource efficiency are required.\n",
    "\n",
    "* `multiprocessing` provides the `multiprocessing.pool.ThreadPool` class, which replicates the multiprocessing API but uses threads instead of processes.\n",
    "\n",
    "The following shows the last code example modified to use thread pools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 USD =     1.0 USD,   0.912 EUR,    3.96 PLN,    10.4 NOK,    22.4 CZK\n",
      "1 EUR =     1.1 USD,     1.0 EUR,    4.34 PLN,    11.4 NOK,    24.5 CZK\n",
      "1 PLN =   0.253 USD,   0.231 EUR,     1.0 PLN,    2.62 NOK,    5.65 CZK\n",
      "1 NOK =  0.0964 USD,   0.088 EUR,   0.382 PLN,     1.0 NOK,    2.16 CZK\n",
      "1 CZK =  0.0447 USD,  0.0408 EUR,   0.177 PLN,   0.463 NOK,     1.0 CZK\n",
      "\n",
      "time elapsed: 0.88s\n"
     ]
    }
   ],
   "source": [
    "!python _11_Using_multiprocessing_dummy/multiprocessing_dummy.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expert-python-programming-fourth-edition-em7utuy--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
